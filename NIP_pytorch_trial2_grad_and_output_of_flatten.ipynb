{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NIP_pytorch_trial2_grad_and_output_of_flatten.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOk6oq03sCi57TvOK3L33zn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumankmaiti/NIP-Neuron-Label-Inverse-Perturbation/blob/main/NIP_pytorch_trial2_grad_and_output_of_flatten.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kh2AW5EQdVvC"
      },
      "outputs": [],
      "source": [
        "!pip install cleverhans"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "# from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from tqdm.notebook import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "import random\n",
        "import time\n",
        "\n",
        "from absl import app, flags\n",
        "from easydict import EasyDict\n",
        "import torchvision\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\n",
        "from cleverhans.torch.attacks.projected_gradient_descent import (\n",
        "    projected_gradient_descent,\n",
        ")"
      ],
      "metadata": {
        "id": "JOsQ2eVOdiHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "pretrained_model = models.vgg19(pretrained=True)\n",
        "\n",
        "print(pretrained_model)"
      ],
      "metadata": {
        "id": "lImyLBo6djLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_size = 224\n",
        "pretrained_means = [0.485, 0.456, 0.406]\n",
        "pretrained_stds = [0.229, 0.224, 0.225]\n",
        "\n",
        "# train_transforms = transforms.Compose([\n",
        "#                            transforms.Resize(pretrained_size),\n",
        "#                            transforms.RandomRotation(5),\n",
        "#                            transforms.RandomHorizontalFlip(0.5),\n",
        "#                            transforms.RandomCrop(pretrained_size, padding=10),\n",
        "#                            transforms.ToTensor(),\n",
        "#                            transforms.Normalize(mean=pretrained_means,\n",
        "#                                                 std=pretrained_stds)\n",
        "                      #  ])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                           transforms.Resize(pretrained_size),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean=pretrained_means,\n",
        "                                                std=pretrained_stds)\n",
        "                       ])"
      ],
      "metadata": {
        "id": "jc5o06-cdr1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = '.data'\n",
        "\n",
        "# train_data = datasets.CIFAR10(ROOT,\n",
        "#                               train=True,\n",
        "#                               download=True,\n",
        "#                               transform=train_transforms)\n",
        "\n",
        "test_data = datasets.CIFAR10(ROOT,\n",
        "                             train=False,\n",
        "                             download=True,\n",
        "                             transform=test_transforms)\n",
        "\n",
        "# print(f'Number of training examples: {len(train_data)}')\n",
        "# print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "metadata": {
        "id": "TW7xZNHdd111"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "# train_iterator = data.DataLoader(train_data,\n",
        "#                                  shuffle=True,\n",
        "#                                  batch_size=BATCH_SIZE)\n",
        "\n",
        "# valid_iterator = data.DataLoader(valid_data,\n",
        "#                                  batch_size=BATCH_SIZE)\n",
        "\n",
        "test_iterator = data.DataLoader(test_data,\n",
        "                                batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "hQ2UWw1teEhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "qUXBIKVXeRJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store the output of a layer"
      ],
      "metadata": {
        "id": "uExQkXBKKJW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "activation = {}\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activation[name] = output.detach()\n",
        "    return hook"
      ],
      "metadata": {
        "id": "WHK6gRaTB5NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "x6yKsanqILJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_predictions(model, iterator):\n",
        "\n",
        "pretrained_model.eval().to(device)\n",
        "\n",
        "    # images = []\n",
        "original_labels = []\n",
        "probs = []\n",
        "predected_labels = []\n",
        "\n",
        "# with torch.no_grad():\n",
        "\n",
        "for (x, y) in tqdm(test_iterator):\n",
        "\n",
        "    x = x.to(device)\n",
        "    # print(x.shape)\n",
        "\n",
        "    # get activation of flatten layer\n",
        "    pretrained_model.classifier[0].register_forward_hook(get_activation('flatten'))\n",
        "\n",
        "    y_pred = pretrained_model(x)\n",
        "\n",
        "    print(activation['flatten'].shape)       \n",
        "\n",
        "    # get gradient og flatten layer\n",
        "    loss = criterion(y_pred, y)\n",
        "    loss.backward()\n",
        "    flatten_layer_grad = pretrained_model.classifier[0].weight.grad\n",
        "    print(flatten_layer_grad.shape)\n",
        "    \n",
        "    y_pred = F.softmax(y_pred, dim=-1) # column wise softmax\n",
        "    # print(y_pred.shape, y_pred)\n",
        "    prob, class_idx= y_pred.max(1) # returns probabilities and its class id\n",
        "    # print(class_idx)\n",
        "    # print(probs)\n",
        "\n",
        "    # images.append(x.cpu())\n",
        "    original_labels.append(y.cpu())\n",
        "    probs.append(prob.cpu())\n",
        "    predected_labels.append(class_idx.cpu())\n",
        "    print(predected_labels)\n",
        "\n",
        "    # images = torch.cat(images, dim=0)  # concatinate each batch to produce one image set\n",
        "original_labels = torch.cat(original_labels, dim=0) \n",
        "probs = torch.cat(probs, dim=0)\n",
        "predected_labels = torch.cat(predected_labels, dim = 0)\n",
        "\n",
        "    # return labels, probs"
      ],
      "metadata": {
        "id": "kORIjCkAeSjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perturbed image"
      ],
      "metadata": {
        "id": "YJ8Zsptf89vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Evaluate on clean and adversarial data\n",
        "pretrained_model.eval().to(device)\n",
        "\n",
        "adv_img = []\n",
        "for (x, y) in tqdm(test_iterator):\n",
        "\n",
        "  x, y = x.to(device), y.to(device)\n",
        "\n",
        "  x_fgm = fast_gradient_method(pretrained_model, x, 0.3,2)\n",
        "  adv_img.append(x_fgm)\n",
        "    # x_pgd = projected_gradient_descent(net, x, 0.3, 0.01, 50, 2)\n",
        "\n",
        "    \n",
        "    # f, axarr = plt.subplots(1,3)\n",
        "    # axarr[0].imshow(x[10].cpu().detach().permute(1, 2, 0))\n",
        "    # axarr[1].imshow(x_fgm[10].cpu().detach().permute(1, 2, 0))\n",
        "    # axarr[2].imshow(x_pgd[10].cpu().detach().permute(1, 2, 0))\n",
        "    \n",
        "  # _, y_pred = pretrained_model(x).max(1)  # model prediction on clean examples\n",
        "  pretrained_model.classifier[0].register_forward_hook(get_activation('flatten_adv'))\n",
        "    \n",
        "  _, y_pred_fgm = pretrained_model(x_fgm).max(1)  # model prediction on FGM adversarial examples\n",
        "  print(activation['flatten_adv'].shape)    # print(y_pred.shape)\n",
        " \n",
        "  print(y_pred_fgm)\n",
        "    # # _ , y_pred_pgd  =  net ( x_pgd ). max (1)\n",
        "    #   print(\"Original label:\",y, \"\\nPredected label without attack:\", y_pred, \"\\nPredected label after FGM attack:\" , y_pred_fgm,  \"\\nPredected label after PGD attack:\", y_pred_pgd)\n",
        "adv_img = torch.cat(adv_img, dim = 0)\n"
      ],
      "metadata": {
        "id": "PkzZe1PZecY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "chg3r6v0ehVE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}